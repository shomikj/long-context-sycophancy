{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50e5a4ce-bd2d-4246-82d8-644964130ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "from bertopic.representation import OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "from hdbscan import HDBSCAN\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fb37ad8-c2d3-442e-96b7-8e28d14be18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 15:01:31,361 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057795e0d0434789ad2432b4780a07f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 15:01:42,584 - BERTopic - Embedding - Completed ✓\n",
      "2025-09-07 15:01:42,585 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-09-07 15:01:50,037 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-09-07 15:01:50,038 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-09-07 15:01:50,220 - BERTopic - Cluster - Completed ✓\n",
      "2025-09-07 15:01:50,224 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "100%|███████████████████████████████████████████| 35/35 [01:29<00:00,  2.57s/it]\n",
      "2025-09-07 15:03:20,655 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# 1) Load and prepare text\n",
    "df = pd.read_csv(\"../data/interactions.csv\")\n",
    "\n",
    "# combine input/output into a single text field\n",
    "df[\"combined\"] = (df[\"input\"].fillna(\"\").astype(str) + \" \" + df[\"output\"].fillna(\"\").astype(str)).str.strip()\n",
    "\n",
    "# choose docs = one row per interaction (matches probs shape to df rows)\n",
    "docs = df[\"combined\"].tolist()\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=25, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "prompt = \"\"\"\n",
    "Your job is to generate a topic label that represents a type of user query or task for LLMs. \n",
    "\n",
    "Determine the topic label based on the following query-response pairs: \\n[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "Based on the above information, can you give a short label of the topic? Only output your short label with no other text or annotations.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer= tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "# Create your representation model\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "representation_model = OpenAI(\n",
    "    client,\n",
    "    model=\"gpt-4o\",\n",
    "    delay_in_seconds=2,\n",
    "    chat=True,\n",
    "    nr_docs=5,\n",
    "    doc_length=100,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 2) Fit BERTopic\n",
    "umap_model = UMAP(random_state=11)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2)\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    calculate_probabilities=True,\n",
    "    top_n_words=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics_assigned, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# 3) Save topic summary\n",
    "topic_info = topic_model.get_topic_info()  # includes -1 \"outliers\" row first\n",
    "#topic_info.to_csv(\"../data/topics.csv\", index=False)\n",
    "\n",
    "# 4) Build a labeled probability DataFrame (columns = topic names, excluding -1)\n",
    "# The probability matrix `probs` has shape (n_docs, n_topics_without_outliers)\n",
    "# Align names by taking non -1 topics from topic_info in order.\n",
    "non_outlier = topic_info[topic_info[\"Topic\"] != -1].copy()\n",
    "\n",
    "# Ensure we have exactly as many names as there are columns in probs\n",
    "expected_cols = probs.shape[1]\n",
    "names = non_outlier[\"Name\"].tolist()[:expected_cols]\n",
    "ids = non_outlier[\"Topic\"].tolist()[:expected_cols]\n",
    "\n",
    "probs_df = pd.DataFrame(probs, columns=names)\n",
    "\n",
    "# 5) Attach assigned topic and probs to the original rows\n",
    "df_out = df.reset_index(drop=True).copy()\n",
    "df_out[\"assigned_topic\"] = topics_assigned  # the single best topic per row\n",
    "df_out = pd.concat([df_out, probs_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 6) Save\n",
    "#df_out.to_csv(\"../data/interactions_with_topic_probs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b838b251-1a6d-445a-a3b5-f0dcd43b2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info.to_csv(\"../data/topics_reduced.csv\", index=False)\n",
    "df_out.to_csv(\"../data/interactions_with_topic_probs_reduced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6deac10e-f27b-46da-b677-25755d08909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/regression/topic_coefficients.csv\")\n",
    "df = df[df[\"p_value\"]<0.10]\n",
    "df = df[((df[\"coefficient\"]<=-0.04)&(df[\"y_var\"]==\"mimesis\"))|((df[\"coefficient\"]<=-0.005)&(df[\"y_var\"]==\"sycophancy\"))]\n",
    "df = df[df[\"topic_column\"]!=\"X12_Response.Error.Message\"]\n",
    "interactions = pd.read_csv(\"../data/interactions_with_topics.csv\")\n",
    "topics_by_user = interactions.groupby([\"assigned_topic\"])[\"user_id\"].nunique().reset_index()\n",
    "TOPICS_MULTIPLE_USERS = topics_by_user.loc[topics_by_user[\"user_id\"]>=np.median(topics_by_user[\"user_id\"]), \"assigned_topic\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "decc7123-47b1-4092-9113-cf8945156221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sycophancy claude-sonnet-4-20250514 aita\n",
      "1\n",
      "Polite Communication Techniques (-0.03), \n",
      "\n",
      "mimesis claude-sonnet-4-20250514 aita\n",
      "6\n",
      "2025 Release Dates (-0.04), Honda Starter Troubleshooting (-0.04), Cloud Storage Management (-0.05), VS Code Navigation (-0.08), Career Development Strategies (-0.08), Travel and Safety (-0.09), \n",
      "\n",
      "mimesis claude-sonnet-4-20250514 politics\n",
      "4\n",
      "Mechanical Engineering Robotics (-0.08), Cloud Storage Management (-0.08), VS Code Navigation (-0.09), Thermodynamics Applications (-0.15), \n",
      "\n",
      "mimesis gpt-4.1-mini-2025-04-14 aita\n",
      "6\n",
      "Cloud Storage Management (-0.05), Exam and Assignment Structure (-0.07), 2025 Release Dates (-0.09), Classical Latin and Music (-0.10), VS Code Navigation (-0.12), Travel and Safety (-0.14), \n",
      "\n",
      "mimesis gpt-4.1-mini-2025-04-14 politics\n",
      "1\n",
      "Polite Communication Techniques (-0.17), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for y_var in df[\"y_var\"].unique():\n",
    "    curr_out = df[df[\"y_var\"]==y_var]\n",
    "    for model_name in curr_out[\"model_name\"].unique():\n",
    "        for task_name in curr_out[\"task_name\"].unique():\n",
    "            print(y_var, model_name, task_name)\n",
    "            curr = curr_out[curr_out[\"model_name\"]==model_name]\n",
    "            curr = curr[curr[\"task_name\"]==task_name]\n",
    "            curr[\"topic_number\"] = curr[\"topic_column\"].str.extract(r'(\\d+)')\n",
    "            curr[\"topic_number\"] = curr[\"topic_number\"].astype(int)\n",
    "            curr = curr[curr[\"topic_number\"].isin(TOPICS_MULTIPLE_USERS)]\n",
    "            print(len(curr))\n",
    "            #curr[\"topic_column\"] = curr[\"topic_column\"].str.replace(r\"^X\\d+_\", \"\", regex=True)\n",
    "            for i,r in curr.sort_values(by='coefficient', ascending=False).iterrows():\n",
    "                t = r[\"topic_column\"]\n",
    "                t = re.sub(r\"^X\\d+_\", \"\", t)\n",
    "                t = re.sub(r\"\\.\", \" \", t)\n",
    "                coeff = round(r[\"coefficient\"], 2)\n",
    "                coeff_str = f\"{coeff:.2f}\"\n",
    "                print(t, \"(\"+coeff_str+\")\", end=\", \")\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89ff2b01-ad2d-4e7c-8c38-2e69b9c95cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_today_hello_assist_hey</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_welcome_youre_im_day</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_email_thank_casual_formal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2_water_clean_dry_coffee</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4_credit_card_income_bank</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12_occured_generating_sorry_error</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28_conversation_topics_talk_dog</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5_clients_emotions_profile_therapy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18_beans_rice_sauce_pie</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34_points_total_attendance_grade</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            topic_name  user_id\n",
       "1            10_today_hello_assist_hey       24\n",
       "11              1_welcome_youre_im_day       22\n",
       "0          0_email_thank_casual_formal       20\n",
       "22            2_water_clean_dry_coffee       16\n",
       "44           4_credit_card_income_bank       16\n",
       "3    12_occured_generating_sorry_error       13\n",
       "20     28_conversation_topics_talk_dog       13\n",
       "55  5_clients_emotions_profile_therapy       12\n",
       "9              18_beans_rice_sauce_pie       12\n",
       "27    34_points_total_attendance_grade       10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "interactions = pd.read_csv(\"../data/interactions_with_topic_probs.csv\")\n",
    "interactions = interactions.groupby([\"assigned_topic\", \"user_id\"])[\"timestamp\"].count().reset_index()\n",
    "interactions = interactions.rename(columns={\"timestamp\": \"num_queries\"})\n",
    "interactions = interactions[interactions[\"assigned_topic\"]>=0]\n",
    "participants = pd.read_csv(\"../data/participants.csv\")\n",
    "participants = participants[[\"user_id\", \"political_lean\", \"gender\"]]\n",
    "participants.loc[participants[\"political_lean\"].isin([\"Moderate\", \"Conservative\", \"Very Conservative\"]), \"political_lean\"] = \"right\"\n",
    "participants.loc[participants[\"political_lean\"].isin([\"Liberal\", \"Very Liberal\"]), \"political_lean\"] = \"left\"\n",
    "\n",
    "interactions = interactions.merge(participants, on=\"user_id\", how=\"left\")\n",
    "topics = pd.read_csv(\"../data/topics.csv\")\n",
    "topics[\"assigned_topic\"] = topics[\"Topic\"]\n",
    "topics[\"topic_name\"] = topics[\"Name\"]\n",
    "topics = topics[[\"assigned_topic\", \"topic_name\"]]\n",
    "\n",
    "interactions = interactions.merge(topics, on=\"assigned_topic\", how=\"left\")\n",
    "interactions = interactions.drop(columns=[\"assigned_topic\"])\n",
    "\n",
    "interactions = interactions.groupby([\"political_lean\", \"topic_name\"])[\"user_id\"].count().reset_index()\n",
    "participants = pd.read_csv(\"../data/participants.csv\")\n",
    "participants = participants[participants[\"passed_attention\"]==\"yes\"]\n",
    "participants = participants[[\"user_id\", \"political_lean\", \"gender\"]]\n",
    "participants.loc[participants[\"political_lean\"].isin([\"Moderate\", \"Conservative\", \"Very Conservative\"]), \"political_lean\"] = \"right\"\n",
    "participants.loc[participants[\"political_lean\"].isin([\"Liberal\", \"Very Liberal\"]), \"political_lean\"] = \"left\"\n",
    "participants[\"total\"] = participants[\"user_id\"]\n",
    "participants = participants.groupby([\"political_lean\"])[\"total\"].count().reset_index()\n",
    "interactions = interactions.merge(participants, on=\"political_lean\", how=\"left\")\n",
    "interactions[\"prop_users\"] = interactions[\"user_id\"]/interactions[\"total\"]\n",
    "topics_all = interactions.groupby([\"topic_name\"])[\"user_id\"].sum().reset_index()\n",
    "topics_all.sort_values(by='user_id', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce502c8-3298-43aa-9a09-30fb50108562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "35c0dc2b-d34d-49b6-bd35-bf9ba97ed359",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (2182744335.py, line 20)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[216]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcurr = curr[curr[\"topic_number\"]==9]]\u001b[39m\n                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "interactions = pd.read_csv(\"../data/interactions_with_topic_probs.csv\")\n",
    "interactions = interactions.groupby([\"assigned_topic\", \"user_id\"])[\"timestamp\"].count().reset_index()\n",
    "interactions = interactions.rename({\"timestamp\": \"num_queries\"})\n",
    "interactions = interactions[interactions[\"assigned_topic\"]>=0]\n",
    "participants = pd.read_csv(\"../data/participants.csv\")\n",
    "participants = participants[[\"user_id\", \"political_lean\", \"gender\"]]\n",
    "participants.loc[participants[\"political_lean\"].isin([\"Moderate\", \"Conservative\", \"Very Conservative\"]), \"political_lean\"] = \"right\"\n",
    "participants.loc[participants[\"political_lean\"].isin([\"Liberal\", \"Very Liberal\"]), \"political_lean\"] = \"left\"\n",
    "\n",
    "topics_by_demographic = interactions.merge(participants, on=\"user_id\", how=\"left\")\n",
    "\n",
    "for model_name in df[\"model_name\"].unique():\n",
    "    for task_name in df[\"task_name\"].unique():\n",
    "        print(model_name, task_name)\n",
    "        curr = df[df[\"model_name\"]==model_name]\n",
    "        curr = curr[curr[\"task_name\"]==task_name]\n",
    "        curr[\"topic_number\"] = curr[\"topic_column\"].str.extract(r'(\\d+)')\n",
    "        curr[\"topic_number\"] = curr[\"topic_number\"].astype(int)\n",
    "        curr = curr[curr[\"topic_number\"].isin(topics_by_user[\"assigned_topic\"])]\n",
    "        curr = topics_by_demographic[topics_by_demographic[\"assigned_topic\"].isin(curr[\"topic_number\"])].groupby([\"political_lean\", \"gender\"])[\"user_id\"].nunique().reset_index()\n",
    "        print(curr)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9e7406e7-48cf-45f1-9832-4ca1b28ab127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-sonnet-4-20250514 aita\n",
      "[1, 10, 0, 12, 28, 2, 4, 5, 7, 47]\n",
      "\n",
      "claude-sonnet-4-20250514 politics\n",
      "[1, 10, 0, 4, 2, 12, 27, 47, 34, 18]\n",
      "\n",
      "gpt-4.1-mini-2025-04-14 aita\n",
      "[1, 10, 0, 12, 2, 28, 4, 5, 34, 7]\n",
      "\n",
      "gpt-4.1-mini-2025-04-14 politics\n",
      "[1, 0, 10, 12, 4, 2, 5, 47, 27, 34]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "understanding = pd.read_csv(\"../data/survey_results.csv\")\n",
    "understanding = understanding[understanding[\"understanding\"]==5]\n",
    "understanding[[\"participant\", \"understanding\", \"model\", \"task\"]].drop_duplicates()\n",
    "\n",
    "interactions = pd.read_csv(\"../data/interactions_with_topic_probs.csv\")\n",
    "interactions = interactions.groupby([\"assigned_topic\", \"user_id\"])[\"timestamp\"].count().reset_index()\n",
    "interactions = interactions.rename({\"timestamp\": \"num_queries\"})\n",
    "\n",
    "for model_name in understanding[\"model\"].unique():\n",
    "    for task_name in understanding[\"task\"].unique():\n",
    "        print(model_name, task_name)\n",
    "        curr = understanding[(understanding[\"model\"]==model_name)&(understanding[\"task\"]==task_name)]\n",
    "        topics = interactions[interactions[\"user_id\"].isin(curr[\"participant\"])]\n",
    "        topics = topics[topics[\"assigned_topic\"]>=0]\n",
    "        print(topics[\"assigned_topic\"].value_counts().head(10).reset_index()[\"assigned_topic\"].to_list())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "45fc31bb-9a97-48b7-a283-5fd9f9e02c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 10, 12, 4, 2, 5, 47, 27, 34]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4c6a9214-3e8c-4970-a585-3ea147578fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political_lean</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>man</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left</td>\n",
       "      <td>woman</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right</td>\n",
       "      <td>man</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>non-binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>woman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  political_lean      gender  user_id\n",
       "0           left         man        2\n",
       "1           left       woman        3\n",
       "2          right         man        4\n",
       "3          right  non-binary        1\n",
       "4          right       woman        2"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_by_demographic[topics_by_demographic[\"assigned_topic\"].isin(curr[\"topic_number\"])].groupby([\"political_lean\", \"gender\"])[\"user_id\"].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0911f886-7359-4ce1-9368-06d2fe25927c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political_lean</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>man</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left</td>\n",
       "      <td>woman</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right</td>\n",
       "      <td>man</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>non-binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>woman</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  political_lean      gender  user_id\n",
       "0           left         man        3\n",
       "1           left       woman        5\n",
       "2          right         man        9\n",
       "3          right  non-binary        1\n",
       "4          right       woman        4"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779dae2d-8862-4366-9fb3-8f04028c04c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a1012-fabd-4c74-9f79-decb5e1a108f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
