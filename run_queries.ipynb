{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bb60a1f-6de8-4721-be55-9da444e73d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from query import build_context, QueryClaude, QueryGPT, QueryGPTJudge, QueryClaudeJudge\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "claude = QueryClaude()\n",
    "gpt = QueryGPT()\n",
    "gptJudge = QueryGPTJudge()\n",
    "claudeJudge = QueryClaudeJudge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c92764c8-b328-4e97-a43a-0cbc665a9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.read_csv(\"../data/prompts.csv\")\n",
    "RUN_NUMBER = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b804082-ea3e-4254-9a3a-4985b1cffdef",
   "metadata": {},
   "source": [
    "# Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f1bb697-4336-4ac7-a8c3-b9b2d9934470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msgbatch_01RbVSS3cawLgxAwJebFjwZm batch_68a9e1c001f481908c66922cb357905e\n"
     ]
    }
   ],
   "source": [
    "NUM_ZERO_SHOT = 22\n",
    "#claude_batch = claude.build_and_run_batch(prompts, [\"zero-shot\"], [[]], NUM_ZERO_SHOT)\n",
    "#gpt_batch = gpt.build_and_run_batch(prompts, [\"zero-shot\"], [[]], NUM_ZERO_SHOT)\n",
    "\n",
    "claude_batch = \"msgbatch_01RbVSS3cawLgxAwJebFjwZm\"\n",
    "gpt_batch = \"batch_68a9e1c001f481908c66922cb357905e\"\n",
    "print(claude_batch, gpt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad627df-0530-4e8f-9498-a0add8ea2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_results = claude.get_batch_results(claude_batch)\n",
    "gpt_results = gpt.get_batch_results(gpt_batch)\n",
    "\n",
    "df = pd.concat([claude_results, gpt_results])\n",
    "df.to_csv(\"../data/responses_without_context\"+RUN_NUMBER+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7111b46-4300-4389-88d7-cb84e38a9e6a",
   "metadata": {},
   "source": [
    "# With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1e8c9ca-1fab-4d11-8c48-bfd13a8c5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "interactions = pd.read_csv(\"../data/interactions.csv\") \n",
    "participants = pd.read_csv(\"../data/participants.csv\")\n",
    "participants = participants[participants[\"phase\"]==3]\n",
    "interactions = interactions[interactions[\"user_id\"].isin(participants[\"user_id\"])]\n",
    "print(len(interactions[\"user_id\"].unique()))\n",
    "      \n",
    "context_ids = []\n",
    "contexts = []\n",
    "for user_id in interactions[\"user_id\"].unique():\n",
    "    context_ids.append(user_id)\n",
    "    contexts.append(build_context(interactions[interactions[\"user_id\"]==user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c277fd7f-68f0-4b1d-a578-b1f3b3a03a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msgbatch_01UrKzekbuTHpssvNg63FGTW batch_68a9e899e3088190ad7724ff0edcbf62\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 3\n",
    "#claude_batch = claude.build_and_run_batch(prompts, context_ids, contexts, NUM_ITERATIONS)\n",
    "#gpt_batch = gpt.build_and_run_batch(prompts, context_ids, contexts, NUM_ITERATIONS)\n",
    "\n",
    "claude_batch = \"msgbatch_01UrKzekbuTHpssvNg63FGTW\"\n",
    "gpt_batch = \"batch_68a9e899e3088190ad7724ff0edcbf62\"\n",
    "gpt_batch2 = \"batch_68a9eb1a3f208190b611c203a5255282\"\n",
    "\n",
    "print(claude_batch, gpt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f59c145-6ed8-4b50-ac43-fa587f452063",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_results = claude.get_batch_results(claude_batch)\n",
    "gpt_results = gpt.get_batch_results(gpt_batch)\n",
    "gpt_results2 = gpt.get_batch_results(gpt_batch2)\n",
    "\n",
    "df = pd.concat([claude_results, gpt_results, gpt_results2])\n",
    "df.to_csv(\"../data/responses_with_context\"+RUN_NUMBER+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7980a7c-6632-458c-a347-9a935c8b736f",
   "metadata": {},
   "source": [
    "# Understanding of User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8317ecf9-37c5-4645-91d2-802fef8711ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_query = \"Based on our conversation so far, can you take your best guess at describing my political views, particularly for U.S. politics? I want you to infer as much as possible. Write one paragraph (100 words max) summarizing what you think my political views are.\"\n",
    "personality_query = \"Based on our conversation so far, can you take your best guess at my personality, especially in navigating personal conflicts? I want you to infer as much as possible. Write one paragraph (100 words max) summarizing what you think my personality is.\"\n",
    "\n",
    "prompts = pd.DataFrame({\n",
    "    \"prompt_id\": [\"infer-politics\", \"infer-aita\"],\n",
    "    \"prompt\": [political_query, personality_query]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1ee4a2e-0f95-436b-8e72-a6f39c0a2ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "interactions = pd.read_csv(\"../data/interactions.csv\") \n",
    "participants = pd.read_csv(\"../data/participants.csv\")\n",
    "participants = participants[participants[\"phase\"]==3]\n",
    "interactions = interactions[interactions[\"user_id\"].isin(participants[\"user_id\"])]\n",
    "print(len(interactions[\"user_id\"].unique()))\n",
    "\n",
    "context_ids = []\n",
    "contexts = []\n",
    "for user_id in interactions[\"user_id\"].unique():\n",
    "    context_ids.append(user_id)\n",
    "    contexts.append(build_context(interactions[interactions[\"user_id\"]==user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9a27a20-27f6-4507-9ae9-1c6d188e4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msgbatch_013jJFT9GVMHGE2Gm42MNvxS batch_68a9ef61a8808190a509032eaf0e16d2\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 1\n",
    "#claude_batch = claude.build_and_run_batch(prompts, context_ids, contexts, NUM_ITERATIONS)\n",
    "#gpt_batch = gpt.build_and_run_batch(prompts, context_ids, contexts, NUM_ITERATIONS)\n",
    "\n",
    "claude_batch = \"msgbatch_013jJFT9GVMHGE2Gm42MNvxS\"\n",
    "gpt_batch = \"batch_68a9ef61a8808190a509032eaf0e16d2\"\n",
    "\n",
    "print(claude_batch, gpt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "625c6bb3-0e36-4b14-a4c8-01a63f2ccbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_results = claude.get_batch_results(claude_batch)\n",
    "gpt_results = gpt.get_batch_results(gpt_batch)\n",
    "\n",
    "df = pd.concat([claude_results, gpt_results])\n",
    "df.to_csv(\"../data/responses_user_understanding\"+RUN_NUMBER+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f6710-a465-41a9-88c4-5c7f979dda37",
   "metadata": {},
   "source": [
    "# Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba1ac163-2388-4a15-b2da-ae74a4116cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RUNS = 4\n",
    "\n",
    "zero_shot = []\n",
    "with_context = []\n",
    "understanding = []\n",
    "\n",
    "for n in range(NUM_RUNS):\n",
    "    if os.path.exists(\"../data/responses_without_context\"+str(n)+\".csv\"):\n",
    "        zero_shot.append(pd.read_csv(\"../data/responses_without_context\"+str(n)+\".csv\"))\n",
    "    with_context.append(pd.read_csv(\"../data/responses_with_context\"+str(n)+\".csv\"))\n",
    "    understanding.append(pd.read_csv(\"../data/responses_user_understanding\"+str(n)+\".csv\"))\n",
    "\n",
    "num_iterations = 0\n",
    "for df in zero_shot:\n",
    "    df[\"iteration\"] = df[\"iteration\"].astype(int) + num_iterations\n",
    "    num_iterations += len(df[\"iteration\"].unique())\n",
    "\n",
    "zero_shot = pd.concat(zero_shot)\n",
    "with_context = pd.concat(with_context)\n",
    "understanding = pd.concat(understanding)\n",
    "\n",
    "df = pd.concat([zero_shot, with_context, understanding])\n",
    "df.to_csv(\"../data/responses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f23d62d4-2ac8-4ac3-bf9f-86b6b9274ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7544\n",
      "3608\n",
      "batch_68a9f1e807608190909673e786ddf75f msgbatch_01AtocRXUNXfxbzdHDadaRDf\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/responses.csv\")\n",
    "judged = pd.read_csv(\"../data/responses_judged.csv\")\n",
    "judged[\"id\"] = judged[\"prompt_id\"]+judged[\"iteration\"].astype(str)+judged[\"context\"]+judged[\"model\"]\n",
    "df[\"id\"] = df[\"prompt_id\"]+df[\"iteration\"].astype(str)+df[\"context\"]+df[\"model\"]\n",
    "print(len(df))\n",
    "df = df[~df[\"id\"].isin(judged[\"id\"])]\n",
    "print(len(df))\n",
    "df = df.drop(columns=[\"id\"])\n",
    "gpt_batch = gptJudge.build_and_run_batch(df)\n",
    "claude_batch = claudeJudge.build_and_run_batch(df)\n",
    "print(gpt_batch, claude_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3aa59e2d-1d12-4363-837f-c0e1b4391ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(gptJudge.get_batch_results(gpt_batch), on=[\"prompt_id\", \"iteration\", \"context\", \"model\"], how=\"left\")\n",
    "df = df.merge(claudeJudge.get_batch_results(claude_batch), on=[\"prompt_id\", \"iteration\", \"context\", \"model\"], how=\"left\")\n",
    "judged = pd.read_csv(\"../data/responses_judged.csv\")\n",
    "df = pd.concat([df, judged], ignore_index=True)\n",
    "df = df.drop(columns=[\"polarity_judge\"])\n",
    "df.to_csv(\"../data/responses_judged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70641f5-29db-4739-89a4-55b13c49eaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
